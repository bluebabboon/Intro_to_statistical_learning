# In the lab we applied random forests to the Boston data usign mtry=6, using ntree=25
#   and ntree=500,
# Create a plot displaying the test error resulting from random forests on this dataset
#   for a more comprehensive range of values for mtry and ntree
#
# Model your plot after figure 8.10. And then describe results


# mtry indicates the number of predictors that we have to chose for random forest classification
#   Choosign all the predictors in mtry makes is equal to the bagging model.
# Also we can vary the tree size

# Loading the bostondata which is part of mass library
library(MASS)
bostondata = Boston

# loading the random forest libraryj
library(randomForest)

set.seed(1)

train = sample(1:nrow(bostondata),nrow(bostondata)/2)

rf_boston_model = randomForest(medv~. ,
                               data = bostondata[train,],
                               mtry = 6,
                               importance = TRUE
                               )
rf_boston_model

rf_boston_model$forest




























































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































